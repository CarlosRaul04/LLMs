{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch \n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: tensor([    4,  1359,  1058,  1108, 22181,  1532,  1008,  1108,  4264,  8186,\n",
      "         1009, 16696,  6163,  1058,  1108,  4264,  8186,  4949,     5])\n",
      "Decoded Text [CLS] esta es una resena de una pelicula. mision imposible es una pelicula genial [SEP]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es')\n",
    "model = AutoModel.from_pretrained('mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es')\n",
    "\n",
    "#Creamos el texto y tokenizamos \n",
    "text = [\"Esta es una reseña de una película. Mision imposible es una película genial\"]\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "#Ahora vemos los tokens\n",
    "tokens = inputs['input_ids'][0]\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "#Ahora convertimos los tokens a palabras para comprobar que este correcto\n",
    "decoded_text = tokenizer.decode(tokens)\n",
    "print(\"Decoded Text\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distilBert_embeddings(text):\n",
    "    #Tokenizamos el texto\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "    #Generamos los embeddings enviando el input al modelo \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    #Promediamos los embeddings a lo largo de la secuencia\n",
    "        #Extraemo los embeddings\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    pooled_embeddings = torch.mean(embeddings, dim=1)\n",
    "    return pooled_embeddings.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = [\"Esta es una reseña de una película. Mision imposible es una película genial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = {}\n",
    "\n",
    "for word in tqdm(text):\n",
    "    #Generamos el embedding con la función get_bert_embeddings\n",
    "    embedding = get_distilBert_embeddings(word)\n",
    "\n",
    "    #Guardamos el embedding en el diccionario\n",
    "    if len(embedding) == 768:\n",
    "        embeddings_dict[word] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar las palabras en un CSV\n",
    "pd.DataFrame(embeddings_dict.keys()).to_csv(\"words_bert.csv\", index=False, columns=None, sep=\"\\t\")\n",
    "\n",
    "# Guardar los embeddings en otro CSV\n",
    "pd.DataFrame(embeddings_dict.values()).to_csv(\"embeddings_bert.csv\", index=False, columns=None, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
