{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch \n",
    "from typing import List, Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Carga el archivo CSV y retorna un DataFrame.\"\"\"\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Combina las columnas 'title' y 'description_es' en una sola columna 'text'.\"\"\"\n",
    "    df['text'] = df['title']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(text: str, tokenizer: DistilBertTokenizer) -> dict:\n",
    "    \"\"\"Tokeniza el texto utilizando el tokenizer especificado.\"\"\"\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(df: pd.DataFrame, tokenizer: DistilBertTokenizer) -> pd.DataFrame:\n",
    "    \"\"\"Tokeniza todo el dataset y retorna un DataFrame con los tokens.\"\"\"\n",
    "    tokens = df['text'].apply(lambda x: tokenize_function(x, tokenizer))\n",
    "    tokens_df = tokens.apply(lambda x: x['input_ids'].squeeze().tolist()).apply(pd.Series)\n",
    "    return tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokenized_data(df: pd.DataFrame, file_path: str) -> None:\n",
    "    \"\"\"Guarda el DataFrame tokenizado en un archivo CSV.\"\"\"\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text: str, tokenizer: DistilBertTokenizer, model: DistilBertModel) -> torch.Tensor:\n",
    "    \"\"\"Genera embeddings a partir del texto utilizando el modelo y el tokenizer especificados.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Obtener el embedding promedio\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizer'.\n",
      "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Carlos\\AppData\\Local\\Temp\\ipykernel_19764\\4222778056.py\", line 25, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Carlos\\AppData\\Local\\Temp\\ipykernel_19764\\4222778056.py\", line 10, in main\n",
      "    model = DistilBertModel.from_pretrained('mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es')\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\transformers\\modeling_utils.py\", line 3703, in from_pretrained\n",
      "    state_dict = load_state_dict(resolved_archive_file)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\transformers\\modeling_utils.py\", line 575, in load_state_dict\n",
      "    return torch.load(\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\torch\\serialization.py\", line 1037, in load\n",
      "    return _legacy_load(opened_file, map_location, _weights_only_unpickler, **pickle_load_args)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\torch\\serialization.py\", line 1272, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\torch\\_weights_only_unpickler.py\", line 169, in load\n",
      "    self.stack[-1] = func(*args)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\torch\\_utils.py\", line 202, in _rebuild_tensor_v2\n",
      "    tensor = _rebuild_tensor(storage, storage_offset, size, stride)\n",
      "  File \"d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\torch\\_utils.py\", line 180, in _rebuild_tensor\n",
      "    t = torch.empty((0,), dtype=storage.dtype, device=storage._untyped_storage.device)\n",
      "d:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\torch\\_utils.py:180: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  t = torch.empty((0,), dtype=storage.dtype, device=storage._untyped_storage.device)\n",
      "Some weights of DistilBertModel were not initialized from the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.word_embeddings.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.10.attention.q_lin.weight', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.11.attention.q_lin.bias', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.6.attention.k_lin.bias', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.6.attention.out_lin.weight', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.7.ffn.lin2.bias', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.7.output_layer_norm.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.9.sa_layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos tokenizados guardados en 'netflix_titles_tokens.csv'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings generados y guardados en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings_output_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: generate_embeddings(x, tokenizer, model))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convertir los embeddings a DataFrame para guardarlos\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m embeddings_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m embeddings_df\u001b[38;5;241m.\u001b[39mto_csv(embeddings_output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings generados y guardados en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings_output_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\pandas\\core\\frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m             arrays,\n\u001b[0;32m    861\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    877\u001b[0m         {},\n\u001b[0;32m    878\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    882\u001b[0m     )\n",
      "File \u001b[1;32md:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:319\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    314\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_2d(values)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(\n\u001b[0;32m    324\u001b[0m         values,\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m         allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m     )\n",
      "File \u001b[1;32md:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:575\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# we could have a 1-dim or 2-dim list here\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# this is equiv of np.asarray, but does object conversion\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# and platform dtype preservation\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# does not convert e.g. [1, \"a\", True] to [\"1\", \"a\", \"True\"] like\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m#  np.asarray would\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(values[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 575\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m values[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;66;03m# GH#21861 see test_constructor_list_of_lists\u001b[39;00m\n\u001b[0;32m    578\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([convert(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32md:\\Cursos\\Curso BOOTCAMP IA GENERATIVA-SOLUCIONES CON PYTHON\\UNIDAD 4\\Tarea4_Modulo_Embeddings\\myvenv\\lib\\site-packages\\torch\\_tensor.py:1087\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_file_path = 'netflix_titles_es.csv'\n",
    "    tokenized_output_file_path = 'netflix_titles_tokens.csv'\n",
    "    embeddings_output_file_path = 'netflix_titles_embeddings.csv'\n",
    "    \n",
    "    df = load_data(input_file_path)\n",
    "    df = combine_text_columns(df)\n",
    "    \n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es')\n",
    "    model = DistilBertModel.from_pretrained('mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es')\n",
    "    \n",
    "    df_tokens = tokenize_dataset(df, tokenizer)\n",
    "    save_tokenized_data(df_tokens, tokenized_output_file_path)\n",
    "    print(f\"Datos tokenizados guardados en '{tokenized_output_file_path}'\")\n",
    "    \n",
    "    # Generar embeddings para los textos combinados\n",
    "    df['embeddings'] = df['text'].apply(lambda x: generate_embeddings(x, tokenizer, model))\n",
    "    \n",
    "    # Convertir los embeddings a DataFrame para guardarlos\n",
    "    embeddings_df = pd.DataFrame(df['embeddings'].tolist())\n",
    "    embeddings_df.to_csv(embeddings_output_file_path, index=False)\n",
    "    print(f\"Embeddings generados y guardados en '{embeddings_output_file_path}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
